{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b9975",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52ab62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beacc4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Download & point to the right directory\n",
    "path = kagglehub.dataset_download(\"nafishamoin/new-bangladeshi-crop-disease\")\n",
    "dataset_path = \"/Users/sourinrakshit/.cache/kagglehub/datasets/nafishamoin/new-bangladeshi-crop-disease/versions/2/BangladeshiCrops/BangladeshiCrops/Crop___Disease\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f3cfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Dataset class\n",
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _find_classes(self):\n",
    "        classes = []\n",
    "        for main_class in os.listdir(self.root_dir):\n",
    "            main_path = os.path.join(self.root_dir, main_class)\n",
    "            if not os.path.isdir(main_path):\n",
    "                continue\n",
    "            for subclass in os.listdir(main_path):\n",
    "                subclass_path = os.path.join(main_path, subclass)\n",
    "                if not os.path.isdir(subclass_path):\n",
    "                    continue\n",
    "                classes.append(f\"{main_class}_{subclass.split('_')[-3]}_{subclass.split('_')[-2]}_{subclass.split('_')[-1]}\")\n",
    "        classes = sorted(set(classes))\n",
    "        return classes, {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for main_class in os.listdir(self.root_dir):\n",
    "            main_path = os.path.join(self.root_dir, main_class)\n",
    "            if not os.path.isdir(main_path):\n",
    "                continue\n",
    "            for subclass in os.listdir(main_path):\n",
    "                subclass_path = os.path.join(main_path, subclass)\n",
    "                if not os.path.isdir(subclass_path):\n",
    "                    continue\n",
    "                label = self.class_to_idx[f\"{main_class}_{subclass.split('_')[-3]}_{subclass.split('_')[-2]}_{subclass.split('_')[-1]}\"]\n",
    "                for fn in os.listdir(subclass_path):\n",
    "                    file_path = os.path.join(subclass_path, fn)\n",
    "                    if not os.path.isfile(file_path):\n",
    "                        continue\n",
    "                    samples.append((file_path, label))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn, label = self.samples[idx]\n",
    "        img = Image.open(fn).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d6e6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Transforms\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_test_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6085429",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Load dataset & compute class weights\n",
    "full_ds = CropDiseaseDataset(dataset_path, transform=None)\n",
    "labels = [lbl for _, lbl in full_ds.samples]\n",
    "num_classes = len(full_ds.classes)\n",
    "cw = compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=labels)\n",
    "class_weights = torch.tensor(cw, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf57fa5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Stratified split\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_val_idx, test_idx = next(sss1.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "train_val_labels = [labels[i] for i in train_val_idx]\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss2.split(np.zeros(len(train_val_labels)), train_val_labels))\n",
    "\n",
    "train_idx = [train_val_idx[i] for i in train_idx]\n",
    "val_idx = [train_val_idx[i] for i in val_idx]\n",
    "\n",
    "train_ds = Subset(full_ds, train_idx)\n",
    "train_ds.dataset.transform = train_tf\n",
    "\n",
    "val_ds = Subset(full_ds, val_idx)\n",
    "val_ds.dataset.transform = val_test_tf\n",
    "\n",
    "test_ds = Subset(full_ds, test_idx)\n",
    "test_ds.dataset.transform = val_test_tf\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9122b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Model\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128*28*28,512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = BasicCNN(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509f919",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 7. Loss, optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948eda4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
